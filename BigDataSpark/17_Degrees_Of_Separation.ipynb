{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17_Degrees_Of_Separation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qATodf61d8EZ",
        "outputId": "ccff1570-43aa-48de-dbcd-6ef500fea5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 46 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 65.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=c1071369f2017db1f3dfecfb6f0868ecf33b3c627698ce8f82c6d24a5ef27ca3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Boilerplate stuff:\n",
        "from pyspark import SparkConf, SparkContext"
      ],
      "metadata": {
        "id": "BuVsmEWCeKQj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setMaster(\"local\").setAppName(\"DegreesOfSeparation\")\n",
        "sc = SparkContext(conf = conf)"
      ],
      "metadata": {
        "id": "nmduQ5-SeMVO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The characters we wish to find the degree of separation between:\n",
        "startCharacterID = 5306 #SpiderMan\n",
        "targetCharacterID = 14  #ADAM 3,031 (who?)\n",
        "\n",
        "# Our accumulator, used to signal when we find the target character during\n",
        "# our BFS traversal.\n",
        "hitCounter = sc.accumulator(0)"
      ],
      "metadata": {
        "id": "nzwSOL4veROv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertToBFS(line):\n",
        "    fields = line.split()\n",
        "    heroID = int(fields[0])\n",
        "    connections = []\n",
        "    for connection in fields[1:]:\n",
        "        connections.append(int(connection))\n",
        "\n",
        "    color = 'WHITE'\n",
        "    distance = 9999\n",
        "\n",
        "    if (heroID == startCharacterID):\n",
        "        color = 'GRAY'\n",
        "        distance = 0\n",
        "\n",
        "    return (heroID, (connections, distance, color))"
      ],
      "metadata": {
        "id": "cKJftuPLeYcV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createStartingRdd():\n",
        "    inputFile = sc.textFile(\"/content/drive/MyDrive/SparkCourse/Marvel-Graph\")\n",
        "    return inputFile.map(convertToBFS)"
      ],
      "metadata": {
        "id": "M8USKjzUecuu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bfsMap(node):\n",
        "    characterID = node[0]\n",
        "    data = node[1]\n",
        "    connections = data[0]\n",
        "    distance = data[1]\n",
        "    color = data[2]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    #If this node needs to be expanded...\n",
        "    if (color == 'GRAY'):\n",
        "        for connection in connections:\n",
        "            newCharacterID = connection\n",
        "            newDistance = distance + 1\n",
        "            newColor = 'GRAY'\n",
        "            if (targetCharacterID == connection):\n",
        "                hitCounter.add(1)\n",
        "\n",
        "            newEntry = (newCharacterID, ([], newDistance, newColor))\n",
        "            results.append(newEntry)\n",
        "\n",
        "        #We've processed this node, so color it black\n",
        "        color = 'BLACK'\n",
        "\n",
        "    #Emit the input node so we don't lose it.\n",
        "    results.append( (characterID, (connections, distance, color)) )\n",
        "    return results"
      ],
      "metadata": {
        "id": "2dyicnUcekyy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bfsReduce(data1, data2):\n",
        "    edges1 = data1[0]\n",
        "    edges2 = data2[0]\n",
        "    distance1 = data1[1]\n",
        "    distance2 = data2[1]\n",
        "    color1 = data1[2]\n",
        "    color2 = data2[2]\n",
        "\n",
        "    distance = 9999\n",
        "    color = color1\n",
        "    edges = []\n",
        "\n",
        "    # See if one is the original node with its connections.\n",
        "    # If so preserve them.\n",
        "    if (len(edges1) > 0):\n",
        "        edges.extend(edges1)\n",
        "    if (len(edges2) > 0):\n",
        "        edges.extend(edges2)\n",
        "\n",
        "    # Preserve minimum distance\n",
        "    if (distance1 < distance):\n",
        "        distance = distance1\n",
        "\n",
        "    if (distance2 < distance):\n",
        "        distance = distance2\n",
        "\n",
        "    # Preserve darkest color\n",
        "    if (color1 == 'WHITE' and (color2 == 'GRAY' or color2 == 'BLACK')):\n",
        "        color = color2\n",
        "\n",
        "    if (color1 == 'GRAY' and color2 == 'BLACK'):\n",
        "        color = color2\n",
        "\n",
        "    if (color2 == 'WHITE' and (color1 == 'GRAY' or color1 == 'BLACK')):\n",
        "        color = color1\n",
        "\n",
        "    if (color2 == 'GRAY' and color1 == 'BLACK'):\n",
        "        color = color1\n",
        "\n",
        "    return (edges, distance, color)"
      ],
      "metadata": {
        "id": "X_cOdoZEerpK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Main program here:\n",
        "iterationRdd = createStartingRdd()\n",
        "\n",
        "for iteration in range(0, 10):\n",
        "    print(\"Running BFS iteration# \" + str(iteration+1))\n",
        "\n",
        "    # Create new vertices as needed to darken or reduce distances in the\n",
        "    # reduce stage. If we encounter the node we're looking for as a GRAY\n",
        "    # node, increment our accumulator to signal that we're done.\n",
        "    mapped = iterationRdd.flatMap(bfsMap)\n",
        "\n",
        "    # Note that mapped.count() action here forces the RDD to be evaluated, and\n",
        "    # that's the only reason our accumulator is actually updated.\n",
        "    print(\"Processing \" + str(mapped.count()) + \" values.\")\n",
        "\n",
        "    if (hitCounter.value > 0):\n",
        "        print(\"Hit the target character! From \" + str(hitCounter.value) \\\n",
        "            + \" different direction(s).\")\n",
        "        break\n",
        "\n",
        "    # Reducer combines data for each character ID, preserving the darkest\n",
        "    # color and shortest path.\n",
        "    iterationRdd = mapped.reduceByKey(bfsReduce)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_sy-BeHe02o",
        "outputId": "925103ab-cb6a-41da-a48f-e8a8eadb99c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running BFS iteration# 1\n",
            "Processing 8330 values.\n",
            "Running BFS iteration# 2\n",
            "Processing 220615 values.\n",
            "Hit the target character! From 1 different direction(s).\n"
          ]
        }
      ]
    }
  ]
}